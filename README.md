
# ğŸ—ï¸ From ML Project to Data Science: Building Workflows That Actually Scale

This repository demonstrates how to take a simple machine learning model and turn it into a **production-ready ML workflow** using **ZenML**, **MLflow**, and **modular design patterns**. The project uses the [Ames Housing dataset](https://www.kaggle.com/datasets/prevek18/ames-housing-dataset) to predict house prices, but the focus is on **workflow thinking** and **MLOps best practices**â€”not just accuracy.

> ğŸ“˜ [Read the full Medium article](https://medium.com/@revati.bhavsar/from-ml-project-to-data-science-building-workflows-that-actually-scale-3235ce8cf10d)

## ğŸš€ Key Concepts Demonstrated

-  **Modular Pipelines** with [ZenML](https://zenml.io/)
-  **Reusable Design Patterns** (Factory, Strategy, Template)
-  **MLflow** for experiment tracking and model registry
-  Clean separation of ingestion, preprocessing, training, evaluation, and deployment
-  CI/CD and MLOps-ready structure

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ analysis/              # EDA modules (univariate, bivariate, etc.)
â”œâ”€â”€ data/                  # Input and output datasets
â”œâ”€â”€ explanations/          # Demo files for design patterns
â”œâ”€â”€ extracted_data/        # Cleaned output from data ingestion
â”œâ”€â”€ mlruns/                # MLflow metadata
â”œâ”€â”€ pipelines/             # ZenML pipeline definitions
â”œâ”€â”€ src/                   # Utility functions and helper classes
â”œâ”€â”€ steps/                 # Modular ZenML pipeline steps
â”œâ”€â”€ config.yaml            # Runtime configuration
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ run_pipeline.py        # Training pipeline entrypoint
â”œâ”€â”€ run_deployment.py      # Deployment pipeline entrypoint
â””â”€â”€ sample_predict.py      # Batch inference script
```

## ğŸ§ª How to Run Locally

1. **Install dependencies**  
   ```bash
   pip install -r requirements.txt
   ```

2. **Initialize ZenML**  
   ```bash
   zenml init
   ```

3. **Run the full training pipeline**  
   ```bash
   python run_pipeline.py
   ```

4. **Deploy the model**  
   ```bash
   python run_deployment.py
   ```

5. **Run batch inference**  
   ```bash
   python sample_predict.py
   ```

## ğŸ§  What Youâ€™ll Learn

This project is ideal for:
- Aspiring **data scientists** who want to transition from notebooks to scalable workflows
- **MLOps enthusiasts** looking to build reproducible and modular ML systems
- Engineers who want to **apply software design patterns** to data pipelines


## ğŸ™‹â€â™€ï¸ Author

**Revati Bhavsar**  
[LinkedIn](https://linkedin.com/in/revatibhavsar) | [Medium](https://medium.com/@revati.bhavsar) | [GitHub](https://github.com/RevatiBhavsar)

## â­ï¸ If you find this helpfulâ€¦

- Drop a â­ï¸ on this repo  
- Share the [Medium article](https://medium.com/@revati.bhavsar/from-ml-project-to-data-science-building-workflows-that-actually-scale-3235ce8cf10d)  
- Reach out for collaborations or hiring discussions!
